{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T17:26:34.697691Z","iopub.execute_input":"2025-03-07T17:26:34.697978Z","iopub.status.idle":"2025-03-07T17:26:39.121781Z","shell.execute_reply.started":"2025-03-07T17:26:34.697955Z","shell.execute_reply":"2025-03-07T17:26:39.120722Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom transformers import MBartForConditionalGeneration, MBartTokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T17:26:39.123251Z","iopub.execute_input":"2025-03-07T17:26:39.123586Z","iopub.status.idle":"2025-03-07T17:26:59.670517Z","shell.execute_reply.started":"2025-03-07T17:26:39.123556Z","shell.execute_reply":"2025-03-07T17:26:59.669814Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"model_name = 'facebook/mbart-large-50-many-to-many-mmt'\ntokenizer = MBartTokenizer.from_pretrained(model_name)\nmodel = MBartForConditionalGeneration.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T17:26:59.672059Z","iopub.execute_input":"2025-03-07T17:26:59.672572Z","iopub.status.idle":"2025-03-07T17:27:17.958591Z","shell.execute_reply.started":"2025-03-07T17:26:59.672547Z","shell.execute_reply":"2025-03-07T17:27:17.957658Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/529 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c1841109dcf418881c82c9f5835c8de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d384106fa0de49748e80367abf944ce7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/649 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef847cf46e0949b89c63d84ef98ea38a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.43k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc74acc2898b4b1a909c7ee8c2de7d1d"}},"metadata":{}},{"name":"stderr","text":"The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \nThe tokenizer class you load from this checkpoint is 'MBart50Tokenizer'. \nThe class this function is called from is 'MBartTokenizer'.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.44G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"151af8c9ae1546b2a7d3028306376cd9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/261 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b93578d7154479882c4c8b272ca0f25"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"text = \"Hello, how are you?\"\n\ninputs = tokenizer(text, return_tensors='pt')\nprint(inputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T17:27:17.959850Z","iopub.execute_input":"2025-03-07T17:27:17.960055Z","iopub.status.idle":"2025-03-07T17:27:17.971585Z","shell.execute_reply.started":"2025-03-07T17:27:17.960036Z","shell.execute_reply":"2025-03-07T17:27:17.970766Z"}},"outputs":[{"name":"stdout","text":"{'input_ids': tensor([[ 35378,      4,   3642,    621,    398,     32,      2, 250004]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"src_lang = 'en_XX'\ntgt_lang = 'fr_XX'\n\nforced_bos_token_id = tokenizer.lang_code_to_id[tgt_lang]\nprint(\"Target language ID : \", forced_bos_token_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T17:27:17.972473Z","iopub.execute_input":"2025-03-07T17:27:17.972777Z","iopub.status.idle":"2025-03-07T17:27:24.470657Z","shell.execute_reply.started":"2025-03-07T17:27:17.972747Z","shell.execute_reply":"2025-03-07T17:27:24.469688Z"}},"outputs":[{"name":"stdout","text":"Target language ID :  250008\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"output = model.generate(**inputs, forced_bos_token_id = forced_bos_token_id)\nprint(\"Generated token IDs :\", output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T17:27:24.471533Z","iopub.execute_input":"2025-03-07T17:27:24.471766Z","iopub.status.idle":"2025-03-07T17:27:26.757815Z","shell.execute_reply.started":"2025-03-07T17:27:24.471745Z","shell.execute_reply":"2025-03-07T17:27:26.756921Z"}},"outputs":[{"name":"stdout","text":"Generated token IDs : tensor([[     2, 250008,  84602,      4,   6868,    307,      9,     18,      9,\n            379,     32,      2]])\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"translated_text = tokenizer.decode(output[0], skip_special_tokens=True)\nprint(\"Translated text : \", translated_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T17:27:26.758620Z","iopub.execute_input":"2025-03-07T17:27:26.758854Z","iopub.status.idle":"2025-03-07T17:27:26.764552Z","shell.execute_reply.started":"2025-03-07T17:27:26.758834Z","shell.execute_reply":"2025-03-07T17:27:26.763514Z"}},"outputs":[{"name":"stdout","text":"Translated text :  Bonjour, comment va-t-il?\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## Fine-tuning on OPUS books dataset","metadata":{}},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\nfrom datasets import load_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T17:27:26.766808Z","iopub.execute_input":"2025-03-07T17:27:26.767037Z","iopub.status.idle":"2025-03-07T17:27:29.127323Z","shell.execute_reply.started":"2025-03-07T17:27:26.767006Z","shell.execute_reply":"2025-03-07T17:27:29.126437Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"dataset = load_dataset('Helsinki-NLP/opus_books', 'en-fr')\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T17:27:29.128583Z","iopub.execute_input":"2025-03-07T17:27:29.129209Z","iopub.status.idle":"2025-03-07T17:27:31.520476Z","shell.execute_reply.started":"2025-03-07T17:27:29.129182Z","shell.execute_reply":"2025-03-07T17:27:31.519755Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/28.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"107cbcfd80ed40a3858164e8bc1e385b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5738b4b3e834572be4d02f394bd5d95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/127085 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b7248c84742468f8e6955b98ff481aa"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'translation'],\n        num_rows: 127085\n    })\n})"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"dataset = dataset['train'].select(range(1000))\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T17:27:31.521179Z","iopub.execute_input":"2025-03-07T17:27:31.521410Z","iopub.status.idle":"2025-03-07T17:27:31.528524Z","shell.execute_reply.started":"2025-03-07T17:27:31.521368Z","shell.execute_reply":"2025-03-07T17:27:31.527818Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['id', 'translation'],\n    num_rows: 1000\n})"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"split_dataset = dataset.train_test_split(test_size=0.2, seed = 42)\nprint(split_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T17:27:31.529265Z","iopub.execute_input":"2025-03-07T17:27:31.529585Z","iopub.status.idle":"2025-03-07T17:27:31.563574Z","shell.execute_reply.started":"2025-03-07T17:27:31.529553Z","shell.execute_reply":"2025-03-07T17:27:31.562585Z"}},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'translation'],\n        num_rows: 800\n    })\n    test: Dataset({\n        features: ['id', 'translation'],\n        num_rows: 200\n    })\n})\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"split_dataset['train'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T17:27:31.564524Z","iopub.execute_input":"2025-03-07T17:27:31.564804Z","iopub.status.idle":"2025-03-07T17:27:31.576227Z","shell.execute_reply.started":"2025-03-07T17:27:31.564780Z","shell.execute_reply":"2025-03-07T17:27:31.575610Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'id': '911',\n 'translation': {'en': 'The old lady, shaky and worn with age, never ceased chatting and laughing.',\n  'fr': 'La vieille dame, cassée, tremblante, ne cessait de causer gaiement et de rire.'}}"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"def preprocess_data(examples):\n    inputs = [ex['en'] for ex in examples['translation']]\n    targets = [ex['fr'] for ex in examples['translation']]\n\n    model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding = \"max_length\")\n    labels = tokenizer(targets, max_length = 128, truncation =True, padding = \"max_length\")\n\n    model_inputs['labels'] = labels['input_ids']\n    return model_inputs\n\ntokenized_datasets = split_dataset.map(preprocess_data, batched=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T17:27:31.577063Z","iopub.execute_input":"2025-03-07T17:27:31.577343Z","iopub.status.idle":"2025-03-07T17:27:32.131566Z","shell.execute_reply.started":"2025-03-07T17:27:31.577315Z","shell.execute_reply":"2025-03-07T17:27:32.130629Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/800 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9f193d641ea400498830fcd73d2e691"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a75682caecd4bd09a76168215aaef56"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"tokenized_datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T17:27:32.132511Z","iopub.execute_input":"2025-03-07T17:27:32.132829Z","iopub.status.idle":"2025-03-07T17:27:32.137653Z","shell.execute_reply.started":"2025-03-07T17:27:32.132797Z","shell.execute_reply":"2025-03-07T17:27:32.136849Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'translation', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 800\n    })\n    test: Dataset({\n        features: ['id', 'translation', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 200\n    })\n})"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T17:27:32.138330Z","iopub.execute_input":"2025-03-07T17:27:32.138595Z","iopub.status.idle":"2025-03-07T17:27:36.817939Z","shell.execute_reply.started":"2025-03-07T17:27:32.138574Z","shell.execute_reply":"2025-03-07T17:27:36.817226Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"/kaggle/working/\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    save_strategy=\"epoch\",\n    # logging_dir=\"/kaggle/working/logs/\",\n    logging_steps=20,\n    report_to=\"tensorboard\",\n    save_total_limit=1\n    # push_to_hub=False,  # Set to True if you want to push to Hugging Face Hub\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T17:27:36.819019Z","iopub.execute_input":"2025-03-07T17:27:36.819258Z","iopub.status.idle":"2025-03-07T17:27:36.954652Z","shell.execute_reply.started":"2025-03-07T17:27:36.819236Z","shell.execute_reply":"2025-03-07T17:27:36.953652Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"test\"],\n    tokenizer=tokenizer,\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T17:27:36.955770Z","iopub.execute_input":"2025-03-07T17:27:36.956008Z","iopub.status.idle":"2025-03-07T17:33:49.419682Z","shell.execute_reply.started":"2025-03-07T17:27:36.955987Z","shell.execute_reply":"2025-03-07T17:33:49.418927Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-17-b984c01b3915>:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [600/600 06:09, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.504900</td>\n      <td>0.432628</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.275300</td>\n      <td>0.420200</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.203400</td>\n      <td>0.437498</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=600, training_loss=0.997893956899643, metrics={'train_runtime': 370.5236, 'train_samples_per_second': 6.477, 'train_steps_per_second': 1.619, 'total_flos': 650138930380800.0, 'train_loss': 0.997893956899643, 'epoch': 3.0})"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"trainer.save_model(\"/kaggle/working/mbart-finetuned-en-fr\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T17:33:49.420448Z","iopub.execute_input":"2025-03-07T17:33:49.420676Z","iopub.status.idle":"2025-03-07T17:33:54.882767Z","shell.execute_reply.started":"2025-03-07T17:33:49.420657Z","shell.execute_reply":"2025-03-07T17:33:54.881765Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"import torch\n\n# Ensure model is on the correct device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Test Translation\ntext = \"This is an amazing book.\"\ninputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n\n# Move input tensors to the same device as the model\ninputs = {key: value.to(device) for key, value in inputs.items()}\n\n# Set the target language\nforced_bos_token_id = tokenizer.lang_code_to_id[tgt_lang]\n\n# Generate translation\noutput = model.generate(**inputs, forced_bos_token_id=forced_bos_token_id)\ntranslated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n\nprint(\"Translated Text:\", translated_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T17:35:41.103885Z","iopub.execute_input":"2025-03-07T17:35:41.104319Z","iopub.status.idle":"2025-03-07T17:35:41.560496Z","shell.execute_reply.started":"2025-03-07T17:35:41.104279Z","shell.execute_reply":"2025-03-07T17:35:41.559760Z"}},"outputs":[{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"name":"stdout","text":"Translated Text: C’est un livre extraordinaire.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}